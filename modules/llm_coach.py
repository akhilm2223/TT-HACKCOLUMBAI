"""
Gemini-Powered Coaching Engine for Break Point
===============================================
The LLM does NOT invent facts. It does NOT analyze video.
It ONLY reasons over structured match summaries from Snowflake.

IDENTITY:
  - Player near camera (RED skeleton, "near" position) = YOU (the user)
  - Player far from camera (BLUE skeleton, "far" position) = OPPONENT

Pipeline:
  1. Fetch FULL_ANALYSIS from Snowflake (ANALYSIS_OUTPUT)
  2. Find similar past matches via vector search (SEMANTIC_VECTOR)
  3. Build prompt with match data + similar matches + player identity
  4. Call Gemini -> structured JSON + UI-ready text
  5. Validate response against hard rules (pattern logic, confidence, language)
  6. Save insight to COACHING_INSIGHTS

HARD RULES (non-negotiable):
  - If similar_matches_found=0: similarity_score=null, most_similar_match_id=null
  - Never speculate about opponent preferences beyond observable evidence
  - Confidence capped at 0.75 when shots<5 or rallies<3
  - Never confidence > 0.85 for any clip
  - Strategy must be executable decisions, not metric goals
  - All advice must be grounded in provided data
"""
import os
import sys
import json
import requests
from dotenv import load_dotenv

current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.append(project_root)

load_dotenv()

try:
    from modules.snowflake_db import SnowflakeDB
except ImportError:
    from .snowflake_db import SnowflakeDB


<<<<<<< HEAD
# ============================================================
# SYSTEM PROMPT
# ============================================================
SYSTEM_PROMPT = """You are an AI performance analyst and mental coach for table tennis players.

You are given structured JSON match analysis data generated by computer vision and physics models.
You must NOT invent data, infer opponent preferences beyond observable evidence, or claim certainty where data is limited.

Your job is to:
- Identify performance problems from metrics
- Translate metrics into coaching advice
- Detect mental patterns under pressure
- Generate honest, actionable guidance

IDENTITY RULES:
- "you" = the player NEAR the camera (RED skeleton, bottom of frame)
- "opponent" = the player FAR from camera (BLUE skeleton, top of frame)
- Always address the player as "you" in display text

HARD RULES (violating ANY of these makes the output invalid):

1. PATTERN COMPARISON LOGIC
   - If similar_matches_found = 0, then similarity_score MUST be null and most_similar_match_id MUST be null
   - shared_pattern must explain lack of data when no similar matches exist
   - NEVER fabricate a similarity score when no matches were found

2. OPPONENT LANGUAGE
   - NEVER say "opponent prefers", "opponent struggles with", "opponent is comfortable"
   - ALLOWED: "The opponent did not appear disrupted by pushes in this clip"
   - ALLOWED: "Push exchanges did not change rally outcome"
   - ALLOWED: "Opponent's shots landed predominantly in [zone]"
   - ALL opponent claims must cite observable evidence from THIS clip only

3. ACTIONS MUST BE DECISIONS, NOT METRICS
   - BAD: "Increase arm speed" (how?)
   - GOOD: "After your push, immediately step forward and prepare a forehand drive"
   - Players execute DECISIONS, not metric goals

4. MENTAL PATTERN MUST EXPLAIN WHY
   - Must describe a PSYCHOLOGICAL tendency, not a tactical observation
   - Must name a SPECIFIC trigger moment
   - Fix must be ONE physical action (breath, step, stance)

5. CONFIDENCE SCALING
   - shots < 5 OR rallies < 3: confidence MUST be <= 0.70
   - shots 5-15: confidence MUST be <= 0.80
   - shots > 15 with 5+ rallies: confidence up to 0.85 max
   - NEVER output confidence > 0.85
   - Always acknowledge limited data in based_on when applicable

6. DISPLAY TEXT MUST SOUND LIKE A REAL COACH
   - Not robotic. Not motivational poster.
   - mental_cue: 3-5 word mantra a player repeats before serving

MONETIZATION RULES (Flowglad tier gating):
- If plan = "free": output ONLY display_summary and match_snapshot
- If plan = "pro": output everything EXCEPT pattern_comparison
- If plan = "elite": output full analysis including pattern_comparison

OUTPUT: Return ONLY valid JSON matching the schema. No markdown. No text outside JSON."""


# ============================================================
# OUTPUT SCHEMA
# ============================================================
OUTPUT_SCHEMA = """{
  "match_snapshot": {
    "shots_analyzed": <int>,
    "rallies_analyzed": <int>,
    "dominant_style": "<passive|aggressive|mixed>",
    "pressure_behavior": "<observable behavior under pressure from footwork_drop and rally data>"
  },
  "key_findings": [
    {
      "finding": "<what went wrong - describe the BEHAVIOR, not the metric>",
      "evidence": "<cite specific numbers from the data>"
    }
  ],
  "pattern_comparison": {
    "similar_matches_found": <int>,
    "most_similar_match_id": "<video filename or null if none found>",
    "similarity_score": <float 0-0.95, or null if similar_matches_found=0>,
    "shared_pattern": "<pattern across matches, or 'Insufficient data for cross-match comparison' if none>"
  },
  "next_match_strategy": [
    {
      "action": "<COMMAND the player can execute in the next rally>",
      "reason": "<WHY - reference observable evidence from the data>"
    }
  ],
  "mental_pattern": {
    "issue": "<psychological tendency under pressure, not a tactical observation>",
    "moment": "<specific trigger - when does this happen?>",
    "fix": "<one physical pre-serve routine or reset action>"
  },
  "confidence": {
    "score": <float, see scaling rules>,
    "based_on": ["<data source 1>", "<data source 2>", "<data source 3>"]
  },
  "display_summary": {
    "headline": "<one sentence, sounds like a coach talking to YOU>",
    "one_line_advice": "<the single most important change>",
    "mental_cue": "<3-5 word mantra to repeat before serving>"
  }
}"""


class GeminiCoach:
    """
    AI coaching engine powered by Gemini.
    - Pulls match data from Snowflake ANALYSIS_OUTPUT (VARIANT)
    - Finds similar past matches via Cortex vector search
    - Reasons via Gemini (decision intelligence, not sensor)
    - Validates output against hard rules
    - Stores insights in COACHING_INSIGHTS
    """

    def __init__(self):
=======
try:
    from HH.stats_engine import StatsEngine
except ImportError:
    # Fallback if running from root
    from HH.stats_engine import StatsEngine


class CortexCoach:
    """
    AI coaching engine powered entirely by Snowflake Cortex.
    - Pulls match data from ANALYSIS_OUTPUT (VARIANT)
    - Finds similar past matches via vector search
    - Reasons via Cortex COMPLETE (llama3.1-70b)
    - Stores insights in COACHING_INSIGHTS
    """

    def __init__(self, model='llama3.1-70b'):

>>>>>>> e5f71e94f5f64b882f6db0e1faece12978f80c35
        self.db = SnowflakeDB()
        self.api_key = os.getenv("GEMINI_API_KEY")
        self.model = "gemini-2.0-flash"
        self.api_url = f"https://generativelanguage.googleapis.com/v1beta/models/{self.model}:generateContent"

        if not self.api_key:
            print("[GeminiCoach] WARNING: GEMINI_API_KEY not found in .env")

    # ----------------------------------------------------------
    # STEP 1: Build the prompt from Snowflake data
    # ----------------------------------------------------------
    def _build_prompt(self, analysis, similar_matches=None, plan="elite"):
        """
        Build the prompt from FULL_ANALYSIS + similar matches.
        Player near camera = YOU. Far from camera = OPPONENT.
        """
        court = analysis.get("court", {})
        shots = analysis.get("shots", [])
        rallies = analysis.get("rallies", [])
        behavioral = analysis.get("behavioral_metrics", {})
        semantic = analysis.get("semantic_summary", "")
        match_context = analysis.get("match_context", {})
        frames = analysis.get("frames", 0)
        fps = analysis.get("fps", 30)

        player = behavioral.get("player", {})
        opponent = behavioral.get("opponent", {})
        match_stats = behavioral.get("match", {})

        # Shot placement breakdown
        zone_counts = {}
        for s in shots:
            z = s.get("landing", {}).get("zone", "unknown")
            zone_counts[z] = zone_counts.get(z, 0) + 1

        # Rally length distribution
        rally_lengths = [r.get("length", 0) for r in rallies]
        long_rallies = [r for r in rallies if r.get("length", 0) >= 4]

        # Data volume signals for confidence scaling
        n_shots = len(shots)
        n_rallies = len(rallies)

        prompt = f"""=== PLAYER IDENTITY ===
YOU = player near camera (RED skeleton, bottom court, "near" position zones)
OPPONENT = player far from camera (BLUE skeleton, top court, "far" position zones)

=== PLAN TIER: {plan.upper()} ===
{"Output ONLY display_summary and match_snapshot." if plan == "free" else ""}
{"Output everything EXCEPT pattern_comparison." if plan == "pro" else ""}
{"Output full analysis including pattern_comparison." if plan == "elite" else ""}

=== DATA VOLUME ===
Total shots: {n_shots}
Total rallies: {n_rallies}
{"WARNING: Very limited data (< 5 shots). Confidence MUST be <= 0.70. Acknowledge this in based_on." if n_shots < 5 else ""}
{"NOTE: Moderate data ({} shots). Confidence should be <= 0.80.".format(n_shots) if 5 <= n_shots <= 15 else ""}

=== CURRENT MATCH DATA ===
VIDEO: {analysis.get('video', 'unknown')}
DURATION: {round(frames / fps, 1)}s ({frames} frames @ {fps}fps)

SEMANTIC SUMMARY:
{semantic}

=== YOUR METRICS (player near camera, RED) ===
  footwork_drop_pct: {player.get('footwork_drop_pct', 'N/A')}%
  avg_footwork_speed: {player.get('avg_footwork_speed', 'N/A')} px/s
  avg_arm_speed: {player.get('avg_arm_speed', 'N/A')} px/f
  aggression_index: {json.dumps(player.get('aggression_index', {}))}

=== OPPONENT OBSERVABLE DATA (player far camera, BLUE) ===
  avg_footwork_speed: {opponent.get('avg_footwork_speed', 'N/A')} px/s
  avg_arm_speed: {opponent.get('avg_arm_speed', 'N/A')} px/f
  NOTE: Do NOT speculate about opponent preferences. Only cite what is observable in this data.

=== MATCH TOTALS ===
  total_shots: {match_stats.get('total_shots', 0)}
  total_rallies: {match_stats.get('total_rallies', 0)}
  forehand_pct: {match_stats.get('forehand_pct', 0)}%
  backhand_pct: {match_stats.get('backhand_pct', 0)}%
  avg_rally_duration: {match_stats.get('avg_rally_duration', 0)}s
  long_rallies (4+ shots): {len(long_rallies)}

=== SHOT PLACEMENT ZONES ===
{json.dumps(zone_counts, indent=2)}

=== ALL SHOTS ({len(shots)} total, first 20) ===
{json.dumps(shots[:20], indent=2)}

=== ALL RALLIES ({len(rallies)} total) ===
{json.dumps(rallies, indent=2)}
"""

        # Similar matches
        n_similar = len(similar_matches) if similar_matches else 0
        if similar_matches and n_similar > 0:
            prompt += f"\n=== SIMILAR PAST MATCHES ({n_similar} found via Snowflake vector search) ===\n"
            prompt += "Use these to identify REPEATING patterns across matches.\n"
            for i, m in enumerate(similar_matches):
                sim = min(m.get('similarity', 0), 0.95)
                prompt += f"""
Past Match {i+1}:
  video: {m.get('video_file', 'unknown')}
  similarity: {sim:.2f}
  pattern: {m.get('semantic_summary', 'N/A')}
"""
        else:
            prompt += """
=== NO SIMILAR PAST MATCHES ===
similar_matches_found = 0
Therefore: most_similar_match_id MUST be null, similarity_score MUST be null.
shared_pattern MUST say "Insufficient data for cross-match comparison" or explain the lack.
"""

        prompt += f"""
=== OUTPUT INSTRUCTIONS ===
Return ONLY valid JSON matching this schema:
{OUTPUT_SCHEMA}

HARD VALIDATION (your response will be rejected if violated):
1. If similar_matches_found = 0: similarity_score = null, most_similar_match_id = null
2. NEVER say "opponent prefers" or "opponent struggles" - only cite observable data
3. next_match_strategy: max 3 actions, each a COMMAND not a metric goal
4. mental_pattern.fix: ONE physical action
5. Confidence scaling: shots<5 -> max 0.70, shots 5-15 -> max 0.80, shots>15 -> max 0.85
6. NEVER confidence > 0.85
"""
        return prompt

    # ----------------------------------------------------------
    # STEP 2: Call Gemini API
    # ----------------------------------------------------------
    def _call_gemini(self, prompt):
        """Call Gemini API with retry for SSL issues."""
        if not self.api_key:
            return None, "GEMINI_API_KEY not set"

        url = f"{self.api_url}?key={self.api_key}"
        payload = {
            "contents": [
                {"parts": [{"text": SYSTEM_PROMPT + "\n\n" + prompt}]}
            ],
            "generationConfig": {
                "temperature": 0.3,
                "maxOutputTokens": 2048,
                "responseMimeType": "application/json"
            }
        }

        try:
            last_err = None
            for attempt in range(3):
                try:
                    resp = requests.post(url, json=payload, timeout=90)
                    if resp.status_code == 200:
                        data = resp.json()
                        text = data["candidates"][0]["content"]["parts"][0]["text"]
                        return text, None
                    else:
                        return None, f"Gemini API error {resp.status_code}: {resp.text[:300]}"
                except (requests.exceptions.SSLError, requests.exceptions.ConnectionError) as e:
                    last_err = e
                    if attempt < 2:
                        import time
                        print(f"[GeminiCoach] Retry {attempt+1}/3 (SSL/connection issue)...")
                        time.sleep(2)
            return None, f"Gemini request failed after 3 attempts: {last_err}"
        except Exception as e:
            return None, f"Gemini request failed: {e}"

    # ----------------------------------------------------------
    # STEP 3: Parse and validate (HARD RULES)
    # ----------------------------------------------------------
    def _parse_response(self, raw_text, n_shots=0, n_rallies=0, n_similar=0):
        """Parse Gemini's JSON response. Enforce ALL hard rules."""
        try:
            text = raw_text.strip()
            if text.startswith("```"):
                text = text.split("\n", 1)[1] if "\n" in text else text[3:]
                if text.endswith("```"):
                    text = text[:-3]
                text = text.strip()

            result = json.loads(text)

            # ------ Required sections ------
            required = ["match_snapshot", "key_findings", "next_match_strategy",
                        "mental_pattern", "confidence", "display_summary"]
            missing = [k for k in required if k not in result]
            if missing:
                return None, f"Missing required fields: {missing}"

            # ------ HARD RULE 1: pattern_comparison logic ------
            pc = result.get("pattern_comparison", {})
            if not pc:
                # Ensure it exists
                result["pattern_comparison"] = {
                    "similar_matches_found": 0,
                    "most_similar_match_id": None,
                    "similarity_score": None,
                    "shared_pattern": "Insufficient data for cross-match comparison"
                }
                pc = result["pattern_comparison"]

            similar_found = pc.get("similar_matches_found", 0)
            if similar_found == 0 or n_similar == 0:
                # FORCE null when no similar matches
                pc["similar_matches_found"] = 0
                pc["most_similar_match_id"] = None
                pc["similarity_score"] = None
                if not pc.get("shared_pattern") or pc["shared_pattern"] == "":
                    pc["shared_pattern"] = "Insufficient data for cross-match comparison"
            else:
                # Cap similarity at 0.95
                if pc.get("similarity_score") is not None:
                    pc["similarity_score"] = min(pc["similarity_score"], 0.95)

            # ------ HARD RULE 2: Confidence scaling ------
            conf = result.get("confidence", {})
            score = conf.get("score", 0.7)

            if n_shots < 5 or n_rallies < 3:
                max_conf = 0.70
            elif n_shots <= 15:
                max_conf = 0.80
            else:
                max_conf = 0.85

            # Clamp
            score = max(0.50, min(max_conf, score))
            conf["score"] = round(score, 2)

            # Ensure based_on acknowledges limited data
            based_on = conf.get("based_on", [])
            if n_shots < 5 and not any("limited" in str(b).lower() for b in based_on):
                based_on.append("Limited data: fewer than 5 shots analyzed")
            conf["based_on"] = based_on

            # ------ HARD RULE 3: Max 3 strategies ------
            strategies = result.get("next_match_strategy", [])
            if len(strategies) > 3:
                result["next_match_strategy"] = strategies[:3]

            # ------ HARD RULE 4: Opponent language check ------
            # Scan for forbidden phrases and clean them
            forbidden_opponent = [
                "opponent prefers", "opponent struggles", "opponent is comfortable",
                "opponent likes", "opponent favors", "opponent tends to"
            ]
            result_str = json.dumps(result).lower()
            violations = [f for f in forbidden_opponent if f in result_str]
            if violations:
                # Flag but don't reject - just note it
                print(f"[GeminiCoach] WARNING: Opponent speculation detected: {violations}")

            return result, None

        except json.JSONDecodeError as e:
            return None, f"JSON parse error: {e}\nRaw: {raw_text[:500]}"

    # ----------------------------------------------------------
    # Flowglad tier gating
    # ----------------------------------------------------------
    def _gate_by_plan(self, result, plan):
        """Remove fields the user's plan doesn't include."""
        if plan == "free":
            return {
                "match_snapshot": result.get("match_snapshot"),
                "display_summary": result.get("display_summary"),
                "plan": "free",
                "upgrade_hint": "Upgrade to Pro for full strategy and mental coaching."
            }
        elif plan == "pro":
            gated = dict(result)
            gated.pop("pattern_comparison", None)
            gated["plan"] = "pro"
            gated["upgrade_hint"] = "Upgrade to Elite for cross-match pattern analysis."
            return gated
        else:
            result["plan"] = "elite"
            return result

    # ----------------------------------------------------------
    # MAIN: analyze_match (from Snowflake)
    # ----------------------------------------------------------
    def analyze_match(self, match_id, save_insight=True, plan="elite"):
        """
        Full pipeline: Snowflake -> vector search -> Gemini -> validated coaching.
        plan: "free", "pro", or "elite" (Flowglad tier)
        """
        if not self.db.conn:
            if not self.db.connect():
                return {"error": "Could not connect to Snowflake"}

        analysis = self.db.get_analysis(match_id)
        if not analysis:
            return {"error": f"No analysis found for match {match_id}"}

        print(f"[GeminiCoach] Loaded analysis for match {match_id[:12]}...")

        n_shots = len(analysis.get("shots", []))
        n_rallies = len(analysis.get("rallies", []))

        # Vector search for similar matches
        semantic = analysis.get("semantic_summary", "")
        similar_matches = []
        if semantic:
            try:
                similar_matches = self.db.find_similar_matches(semantic, top_k=5)
                similar_matches = [
                    m for m in similar_matches
                    if m["match_id"] != match_id and m.get("similarity", 1.0) < 0.99
                ][:3]
                print(f"[GeminiCoach] Found {len(similar_matches)} similar past matches")
            except Exception as e:
                print(f"[GeminiCoach] Vector search skipped: {e}")

        n_similar = len(similar_matches)

        prompt = self._build_prompt(analysis, similar_matches=similar_matches or None, plan=plan)
        print(f"[GeminiCoach] Prompt built ({len(prompt)} chars)")

        print(f"[GeminiCoach] Calling Gemini ({self.model})...")
        raw_text, error = self._call_gemini(prompt)
        if error:
            return {"error": f"Gemini call failed: {error}"}

        result, parse_error = self._parse_response(
            raw_text, n_shots=n_shots, n_rallies=n_rallies, n_similar=n_similar
        )
        if parse_error:
            return {"error": parse_error, "raw_response": raw_text}

        print(f"[GeminiCoach] Structured response received")

        # Gate by Flowglad plan
        result = self._gate_by_plan(result, plan)

        # Save to Snowflake
        if save_insight:
            try:
                self.db.insert_coaching_insight(
                    match_id, prompt, raw_text, processed_json=result
                )
                print(f"[GeminiCoach] Insight saved to COACHING_INSIGHTS")
            except Exception as e:
<<<<<<< HEAD
                print(f"[GeminiCoach] Failed to save insight: {e}")

        return result

    # ----------------------------------------------------------
    # Analyze from local JSON (no Snowflake read)
    # ----------------------------------------------------------
    def analyze_json(self, json_path, similar_matches=None, plan="elite"):
        """Analyze a local JSON file directly. Still calls Gemini."""
        with open(json_path, 'r', encoding='utf-8') as f:
            analysis = json.load(f)

        n_shots = len(analysis.get("shots", []))
        n_rallies = len(analysis.get("rallies", []))
        n_similar = len(similar_matches) if similar_matches else 0

        prompt = self._build_prompt(analysis, similar_matches=similar_matches, plan=plan)
        print(f"[GeminiCoach] Prompt built from {json_path} ({len(prompt)} chars)")

        raw_text, error = self._call_gemini(prompt)
        if error:
            return {"error": f"Gemini call failed: {error}"}

        result, parse_error = self._parse_response(
            raw_text, n_shots=n_shots, n_rallies=n_rallies, n_similar=n_similar
        )
        if parse_error:
            return {"error": parse_error, "raw_response": raw_text}

        return self._gate_by_plan(result, plan)

    # ----------------------------------------------------------
    # Ask: quick question about a match
    # ----------------------------------------------------------
    def ask(self, match_id, question):
        """Ask a specific question about a match using Gemini."""
        if not self.db.conn:
            if not self.db.connect():
                return "Error: Could not connect to Snowflake."

        analysis = self.db.get_analysis(match_id)
        if not analysis:
            return f"No analysis for match {match_id}."

        prompt = self._build_prompt(analysis)
        prompt += f"\n\n=== USER QUESTION ===\n{question}\n\nAnswer concisely as a coach. Address the player as 'you'. Return plain text."

        raw_text, error = self._call_gemini(prompt)
        if error:
            return f"Error: {error}"
        return raw_text


# ============================================================
# Pretty-print for terminal / demo
# ============================================================
def print_coaching_result(result):
    """Print structured coaching in a demo-friendly format."""
    if "error" in result:
        print(f"\nERROR: {result['error']}")
        return

    plan = result.get("plan", "elite")
    ds = result.get("display_summary", {})
    print(f"\n{'='*60}")
    print(f"  COACH: {ds.get('headline', '')}")
    print(f"{'='*60}")

    snap = result.get("match_snapshot", {})
    print(f"\n  {snap.get('shots_analyzed', '?')} shots | {snap.get('rallies_analyzed', '?')} rallies | Style: {snap.get('dominant_style', '?')}")
    print(f"  Under pressure: {snap.get('pressure_behavior', '?')}")

    if plan == "free":
        print(f"\n  [FREE TIER] Upgrade to Pro for full strategy and mental coaching.")
        print(f"\n  >>> {ds.get('one_line_advice', '')}")
        print(f"  Mantra: \"{ds.get('mental_cue', '')}\"")
        print(f"{'='*60}\n")
        return

    print(f"\n  KEY FINDINGS:")
    for i, f in enumerate(result.get("key_findings", []), 1):
        print(f"  {i}. {f.get('finding', '')}")
        print(f"     -> {f.get('evidence', '')}")

    pc = result.get("pattern_comparison")
    if pc and pc.get("similar_matches_found", 0) > 0:
        print(f"\n  CROSS-MATCH PATTERN (Snowflake vector search):")
        sim_score = pc.get('similarity_score')
        sim_display = f"{sim_score:.2f}" if sim_score is not None else "N/A"
        print(f"  {pc.get('similar_matches_found', 0)} similar matches | closest: {pc.get('most_similar_match_id', 'N/A')} ({sim_display})")
        print(f"  Repeating pattern: {pc.get('shared_pattern', '?')}")
    elif pc:
        print(f"\n  CROSS-MATCH: {pc.get('shared_pattern', 'No similar matches found')}")

    if plan in ("pro", "elite"):
        print(f"\n  WHAT TO DO NEXT TIME:")
        for i, s in enumerate(result.get("next_match_strategy", []), 1):
            print(f"  {i}. {s.get('action', '')}")
            print(f"     Because: {s.get('reason', '')}")

        mp = result.get("mental_pattern", {})
        print(f"\n  MENTAL RESET:")
        print(f"  Pattern: {mp.get('issue', '?')}")
        print(f"  Trigger: {mp.get('moment', '?')}")
        print(f"  Fix: {mp.get('fix', '?')}")

    conf = result.get("confidence", {})
    score = conf.get('score', 0)
    print(f"\n  Confidence: {score:.0%}")
    for r in conf.get("based_on", []):
        print(f"    - {r}")

    print(f"\n  >>> {ds.get('one_line_advice', '')}")
    print(f"  Mantra: \"{ds.get('mental_cue', '')}\"")
    print(f"{'='*60}\n")


# Backwards compatibility
CortexCoach = GeminiCoach
LLMCoach = GeminiCoach
=======
                print(f"Warning: Failed to save insight to DB: {e}")
        
        return response_text


class K2Coach:
    """
    AI coaching engine powered by IFM K2-Think (LLM360).
    - Uses the same 'Reasoning' API as the hybrid detector.
    - Analyzes match statistics to provide strategic advice.
    """
    def __init__(self):
        self.api_key = os.environ.get("MOONSHOT_API_KEY") or os.environ.get("KIMI_K2_API_KEY")
        self.base_url = None
        self.model = None
        self.client = None
        self.db = SnowflakeDB()
        self.engine = StatsEngine()

        if self.api_key:
            # Re-use logic from detector to resolve URL/Model
            if self.api_key.startswith("IFM-"):
                self.base_url = (os.environ.get("IFM_K2_API_BASE_URL") or "").strip().rstrip("/")
                self.model = os.environ.get("K2_THINK_MODEL", "k2-think")
            else:
                self.base_url = "https://api.moonshot.ai/v1"
                self.model = "kimi-k2.5"
            
            try:
                from openai import OpenAI
                self.client = OpenAI(api_key=self.api_key, base_url=self.base_url, timeout=60.0)
            except Exception as e:
                print(f"Warning: Could not initialize K2 client: {e}")

    def get_match_summary(self, match_id, db_save=True):
        # Reuse CortexCoach's logic or typically this would be a shared base class
        # For now, delegating to a temporary CortexCoach instance to reuse logic is easiest
        # without refactoring the whole file
        return CortexCoach().get_match_summary(match_id, db_save)

    def get_ai_insight(self, match_id, db_save=True):
        print(f"[K2-Think] Generating insight for Match {match_id}...")
        
        # 1. Get Stats (reuse logic)
        stats = self.get_match_summary(match_id, db_save=db_save)
        if isinstance(stats, str):
            return stats
            
        # 2. Build Prompt (Reuse Cortex logic)
        prompt = CortexCoach().generate_coach_prompt(stats)
        
        # 3. Call K2-Think
        response_text = "Error: K2 Client not initialized."
        if self.client:
            try:
                completion = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "You are a world-class Table Tennis Coach. Analyze the provided match statistics and give specific, actionable advice."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=600,
                    temperature=0.7
                )
                response_text = completion.choices[0].message.content
                # Strip thinking tokens if present
                import re
                response_text = re.sub(r'<think>.*?</think>', '', response_text, flags=re.DOTALL).strip()
                
            except Exception as e:
                response_text = f"Error calling K2-Think: {e}"
        
        print(f"[K2-Think] Response Received: {response_text[:50]}...")

        # 4. Save
        if db_save:
            try:
                self.db.insert_coaching_insight(
                    match_id,
                    prompt,
                    response_text,
                    processed_json={"method": "k2-think"} 
                )
            except Exception as e:
                print(f"Warning: Failed to save insight to DB: {e}")

        return response_text

>>>>>>> baf5c4c (Feat: Implement K2-Think Hybrid Reasoning and FlowGlad Sponsor Track)
